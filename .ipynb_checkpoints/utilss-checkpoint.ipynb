{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9173e7f6-85ee-4020-810f-3b21aad82273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce96657-372e-4140-8ca4-ee868ed96522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load and filter the dataset\n",
    "def load_filter_data(file_path, exclude_type):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file and filters the accommodation types.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): CSV file path.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Reading dataset with index set to false\n",
    "    df = pd.read_csv(file_path, index_col=False)\n",
    "\n",
    "    #To filter the dataset excluding the observation specified\n",
    "    df_filtered= df[df['Main Accommodation Type'] != exclude_type].copy()\n",
    "\n",
    "    #To reindex the dataFrame\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #To filter the dataset ecluding the observation specified\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9e28d7-f3bc-4537-aa6b-6204655633df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the interquartile range and identify outliers\n",
    "def calculate_iqr(df_filtered, feature):\n",
    "    \"\"\"\n",
    "    Calculates interquartiles, IQR, and outliers.\n",
    "    \n",
    "    PArameters:\n",
    "    df_filtered - pandas DataFrame.\n",
    "    feature - feature where the IQR and outliers are going to be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    outliers - DataFrame showing outliers.\n",
    "    \"\"\"\n",
    "\n",
    "    constant = 1.5\n",
    "    #To calculate the 25th percentile (first quartile)\n",
    "    Q1 = df_filtered[feature].quantile(0.25)\n",
    "    #To calculate the 75th percentile (third quartile)\n",
    "    Q3 = df_filtered[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    #To identify outliers\n",
    "    \n",
    "    #Calculates the lower bound\n",
    "    lower = Q1 - constant * IQR\n",
    "    #Calculates the upper bound\n",
    "    upper = Q3 + constant * IQR\n",
    "    \n",
    "    outliers = df_filtered[(df_filtered[feature] < lower) | (df_filtered[feature] > upper)]\n",
    "    \n",
    "    # Returns features specified only\n",
    "    return outliers[['Average Length of Stay of Foreign Visitors (Nights per trip)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416c3f82-4ae0-4454-9d61-4591f5666452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the dataFrame processed\n",
    "def load_and_process_data(df_filtered, outliers):\n",
    "    \"\"\"\n",
    "    Processes the DataFrame by removing outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    df_filtered (pd.DataFrame): DataFrame after initial filtering.\n",
    "    outliers (pd.DataFrame): DataFrame containing outliers.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame without outliers.\n",
    "    \"\"\"\n",
    "    df_no_outliers = df_filtered[~df_filtered.index.isin(outliers.index)]\n",
    "    return df_no_outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c6266-6eca-47a1-b8f1-4866c504a957",
   "metadata": {},
   "source": [
    "## Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e37ca56-6219-49e8-8281-82699a23bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot a heatmap\n",
    "def plot_correlation_heatmap(dataframe, variables, title='Correlation Matrix Heatmap'):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the correlation matrix for the specified variables in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: pd.DataFrame - The DataFrame containing the data.\n",
    "    - variables: list - A list of column names to include in the correlation matrix.\n",
    "    - title: str - The title for the heatmap.\n",
    "    \"\"\"\n",
    "    correlation_matrix = dataframe[variables].corr()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c22ac1c-9f75-44b2-88e3-5c01b6e0f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_poisson_distribution(df_no_outliers, accommodation_type_column, accommodation_type):\n",
    "    \"\"\"\n",
    "    Generates and plots a Poisson distribution for a specific accommodation type.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe containing the data.\n",
    "    accommodation_type_column (str): The name of the column indicating the accommodation type.\n",
    "    accommodation_type (str): The specific accommodation type for the calculation.\n",
    "    \"\"\"\n",
    "    # Filter the dataset for the specific accommodation type\n",
    "    filtered_data = df_no_outliers[df_no_outliers[accommodation_type_column] == accommodation_type]\n",
    "    \n",
    "    # Check if there is data after filtering\n",
    "    if filtered_data.empty:\n",
    "        print(f\"No data found for accommodation type: {accommodation_type}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate Î» as the average nights per month for this accommodation type\n",
    "    lambda_poisson = filtered_data['Month'].mean()\n",
    "    \n",
    "    # Generate the Poisson distribution\n",
    "    np.random.seed(33)  # Set seed for reproducibility\n",
    "    poisson_dist = np.random.poisson(lambda_poisson, 10000)\n",
    "    \n",
    "    # Plot the distribution\n",
    "    plt.hist(poisson_dist, bins=30, density=True, alpha=0.6, color='b')\n",
    "    plt.axvline(x=np.mean(poisson_dist), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(poisson_dist) + 2, plt.ylim()[1] * 0.8, f'Mean: {np.mean(poisson_dist):.2f}', color='r')\n",
    "    plt.title(f'Poisson Distribution of Monthly Nights for {accommodation_type} Accommodation')\n",
    "    plt.xlabel('Number of Nights')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6dfa0-b7cd-411f-a72e-0de36a14fa63",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b826f07-94b6-4a67-aba6-5958867e0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_dataframe(df_no_outliers, columns_to_transform):\n",
    "    \"\"\"\n",
    "    Applies logarithmic transformation to specified columns of the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df_no_outliers: The DataFrame to transform.\n",
    "    columns_to_transform (list): List of column names to apply the transformation.\n",
    "\n",
    "    Returns:\n",
    "    A new DataFrame with transformed columns added.\n",
    "    \"\"\"\n",
    "    #Creates a copy of the original DataFrame to avoid modifying it\n",
    "    transformed_df = df_no_outliers.copy()\n",
    "\n",
    "    #Defines a function to apply logarithmic transformation\n",
    "    def log_transform(column):\n",
    "        return np.log(column + 1)  #to avoid log(0)\n",
    "\n",
    "    #Applies the transformation to the specified columns\n",
    "    for col in columns_to_transform:\n",
    "        transformed_df[f'log_{col}'] = log_transform(transformed_df[col])\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163dcca2-4a50-4f3f-9940-4fe688fa88de",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fc3d3-3255-4487-a80a-b9536ff3141f",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1383abb-e47d-4bd1-a5ef-0af5eec6897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to divide dependant and independant variables\n",
    "def split_features_target(df, target):\n",
    "    \"\"\"\n",
    "    Splits the DataFrame into features and target.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    target (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    X (pd.DataFrame): The DataFrame containing the features.\n",
    "    y (pd.Series): The Series containing the target variable.\n",
    "    \"\"\"\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in DataFrame.\")\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target], axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72af770-5f15-42ab-b1c7-afbaeff7fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to devide data in train and test\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits data into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    X (pd.DataFrame): Features DataFrame.\n",
    "    y (pd.Series): Target Series.\n",
    "    test_size (float): Proportion of the dataset to include in the test split.\n",
    "    random_state (int): Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    X_train, X_test, y_train, y_test: Split datasets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716e301f-d147-4543-ac19-7e58b1410902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to standarize the data\n",
    "def standardize_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardizes the training and test datasets.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training features.\n",
    "    X_test (pd.DataFrame): Test features.\n",
    "\n",
    "    Returns:\n",
    "    X_train_scaled (np.ndarray): Scaled training features.\n",
    "    X_test_scaled (np.ndarray): Scaled test features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34c0826-33f2-46ed-b49b-d13cd1bd70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Ridge regression model using GridSearchCV to find the best hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training features.\n",
    "    y_train (pd.Series): Training target.\n",
    "\n",
    "    Returns:\n",
    "    best_ridge (Ridge): Trained Ridge regression model with the best found hyperparameters.\n",
    "    \"\"\"\n",
    "    #To set up the GridSearchCV with Ridge regression\n",
    "    ridge_cv = GridSearchCV(Ridge(), param_grid={'alpha': [0.01, 0.1, 1, 10, 100]}, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "    #Fitting the model\n",
    "    ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "    #To extract the best model\n",
    "    best_ridge = Ridge(alpha=ridge_cv.best_params_['alpha'])\n",
    "    best_ridge.fit(X_train, y_train)\n",
    "\n",
    "    return best_ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ce44ed-d694-443d-892e-38d99eafa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Lasso regression model using GridSearchCV to find the best hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training features.\n",
    "    y_train (pd.Series): Training target.\n",
    "\n",
    "    Returns:\n",
    "    best_lasso (Lasso): Trained Lasso regression model with the best found hyperparameters.\n",
    "    \"\"\"\n",
    "    #To set up the GridSearchCV with Lasso regression\n",
    "    lasso_cv = GridSearchCV(Lasso(), param_grid={'alpha': [0.01, 0.1, 1, 10, 100]}, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "    #Fitting the model\n",
    "    lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "    #To extract the best model\n",
    "    best_lasso = Lasso(alpha=lasso_cv.best_params_['alpha'])\n",
    "    best_lasso.fit(X_train, y_train)\n",
    "\n",
    "    return best_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed387d0d-5c7d-4956-85b5-766b8e52cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a machine learning model using mean squared error and R-squared metrics.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn model): The trained machine learning model.\n",
    "    X_test (pd.DataFrame): Test features.\n",
    "    y_test (pd.Series): True values for the test set.\n",
    "\n",
    "    Returns:\n",
    "    mse (float): Mean squared error of the model on the test set.\n",
    "    r2 (float): R-squared score of the model on the test set.\n",
    "    \"\"\"\n",
    "    #predicts values using the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #To calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    #To calculate R-squared score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db037f39-94f6-4919-84e0-48a9c27935fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coefficients(model, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Analyzes and prints the coefficients of a linear model.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn model): The trained linear model.\n",
    "    model_name (str): The name of the model.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"{model_name} Coefficients:\", model.coef_)\n",
    "    print(f\"{model_name} Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f72809-2b96-4d2e-abc3-1cd8b5a0a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                    Type        Data/Info\n",
      "-------------------------------------------------\n",
      "GridSearchCV                ABCMeta     <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "Lasso                       ABCMeta     <class 'sklearn.linear_mo<...>oordinate_descent.Lasso'>\n",
      "Ridge                       ABCMeta     <class 'sklearn.linear_model._ridge.Ridge'>\n",
      "StandardScaler              type        <class 'sklearn.preproces<...>ng._data.StandardScaler'>\n",
      "calculate_iqr               function    <function calculate_iqr at 0x000001FFFC747C40>\n",
      "load_and_process_data       function    <function load_and_proces<...>ta at 0x000001FFFC76C040>\n",
      "load_filter_data            function    <function load_filter_data at 0x000001FFFC60F100>\n",
      "mean_squared_error          function    <function mean_squared_er<...>or at 0x000001FFFC5B9300>\n",
      "np                          module      <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd                          module      <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plot_correlation_heatmap    function    <function plot_correlatio<...>ap at 0x000001FFFC76C540>\n",
      "plot_poisson_distribution   function    <function plot_poisson_di<...>on at 0x000001FFFC76CB80>\n",
      "plt                         module      <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "r2_score                    function    <function r2_score at 0x000001FFFC5B9B20>\n",
      "train_test_split            function    <function train_test_split at 0x000001FFFC5F71A0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8a9f2-3bfa-4411-878e-d16a934b7bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0da4f-1163-4325-bcf2-e4c1bc5c73a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28509211-f283-4155-b02a-0bff9a804b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe247b-5178-4edf-ada4-002bc2e7e44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd8ed4-59e3-4f08-9f10-b1bbdf2fbdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052fd8dd-f61c-4320-be62-37d69a56dc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d169c-02d7-46ee-97a9-72e111abcd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
